{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb430a5-2d63-4ec4-baeb-94f32507c25e",
   "metadata": {},
   "source": [
    "## Using Gradient Checkpointing in models using MLFlow experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86edaa8-7a12-4173-bcae-81c97756a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import mlflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60928-0ca3-41aa-b16c-35426b833160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow setup\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"check-localhost-connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4936d-1e2a-4e7d-9a68-d53bfbe60d32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, y_pred, y_true):\n",
    "        ctx.save_for_backward(y_pred, y_true)\n",
    "        y_pred_clipped = torch.clamp(y_pred, 1e-7, 1-1e-7)\n",
    "        loss = torch.sum(-y_true * torch.log(y_pred_clipped)) / y_true.shape[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(ctx, grad_output):\n",
    "        y_pred, y_true = ctx.saved_tensors\n",
    "        N = y_true.shape[0]\n",
    "        dy_pred = (-y_true/y_pred) / N\n",
    "        return grad_output * dy_pred, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8ff1-5bd3-4439-a0d9-222dab7bda45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "A = torch.rand(3,3, requires_grad = True, dtype = torch.double)\n",
    "B = torch.rand(3,3, requires_grad = False, dtype = torch.double)\n",
    "\n",
    "crossentropyloss = CustomLoss.apply\n",
    "\n",
    "torch.autograd.gradcheck(crossentropyloss, [A, B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b5f19-5f32-466b-acb5-88a907e1a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tansforms = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root=\"\\data\", download=True, train=True, transform=transforms.ToTensor())\n",
    "test_dataset = CIFAR10(root=\"\\data\", download = True, train=False, transform = transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 64, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dd8e3-99cf-4796-948d-e26c80f38c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10_Model, self).__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            ])\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(64, 64, 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ])\n",
    "        self.dropout_2 = nn.Dropout(0.25)\n",
    "        self.flatten = lambda input: torch.flatten(input, 1)\n",
    "        self.linearize = nn.Sequential(*[\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "        self.dropout_3 = nn.Dropout(0.5)\n",
    "        self.linear1 = nn.Linear(512, 84)\n",
    "        self.out = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.cnn_block_1(img)\n",
    "        x = self.dropout_1(x)\n",
    "        x = checkpoint(self.cnn_block_2, x, use_reentrant = True)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linearize(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47319d09-e648-464b-8f8c-90f14a4ff292",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CIFAR10_Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f578e44-978f-4d94-b48c-6525ddb8a92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "metric_fn = Accuracy(\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100  == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            step = batch // 100 * (epoch + 1)\n",
    "            mlflow.log_metric(\"Loss\", f\"{loss:2f}\", step = step)\n",
    "            mlflow.log_metric(\"Accuracy\", f\"{accuracy: 2f}\", step = step)\n",
    "            print(f\"loss: {loss:2f} accuracy: {accuracy:2f} [{current} / {len(dataloader)}]\")\n",
    "\n",
    "\n",
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y)\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step = epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy: 2f}\", step = epoch)\n",
    "\n",
    "    print(f\"Eval metrics: \\nAccuracy: {eval_accuracy:.2f}, Avg loss: {eval_loss:2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3509d0-a581-41d8-ad11-0e78ada8078b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\n",
    "        \"epochs\" : epochs,\n",
    "        \"learning_rate\" : 1e-3,\n",
    "        \"batch_size\" : 64,\n",
    "        \"loss_function\" : loss_fn.__class__.__name__,\n",
    "        \"metric_function\" : metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"AdamW\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n----------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optim, epoch = t)\n",
    "        evaluate(test_dataloader, model, loss_fn, metric_fn, epoch = 0)\n",
    "\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
